{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd71786-0c2f-46b3-846b-1d50b51b3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moabb.datasets import BNCI2014001, Cho2017, PhysionetMI,Zhou2016\n",
    "from moabb.paradigms import MotorImagery\n",
    "\n",
    "\n",
    "from mne  import concatenate_epochs\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "path = '/users/local/simpleconv_datasets/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd1a305-2782-44d4-98b9-3e2d05f02130",
   "metadata": {},
   "source": [
    "|           | BNCI | CHO2017 | Physionet| Weibo2014 | Zhou2016 | Shin2017 |\n",
    "| --------  | ---- | -----   | -------- | --------- | -------- | -------- |\n",
    "| BNCI      |22(+2)|   22    |   22     |    22     |     9    |    2     | \n",
    "| CHO2017   |  22  |  64(+5) |   62     |    58     |    14    |   13     |  \n",
    "| Physionet |  22  |  62    |   64     |   58      |   14     |   12     | \n",
    "| Weibo2014 |  22  |  58     |  65     |   60      |   14     |   12     | \n",
    "| Zhou2016  |  9   |   14    |   14     |  14       |  14(+2)  |   1      |   \n",
    "| Shin2017  |  2   |   13    |   12     |  12       |   1      |  30(+3)  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ca7547-a9bd-48ad-a4e3-7f943eaa122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dset,num_classes,selected_chans = None,subjects=None,sfreq = 160,fmin=2,fmax=40,tmin=0,tmax=3):\n",
    "    print(num_classes)\n",
    "    ds_src = dset()\n",
    "    src_prgm = MotorImagery(n_classes=num_classes, channels=selected_chans, resample=sfreq, fmin=fmin, fmax=fmax, tmin=tmin,tmax=tmax)\n",
    "    if not subjects:\n",
    "        epoch_X_src, label_src, m_src = src_prgm.get_data(dataset=ds_src, return_epochs=True)\n",
    "    else : \n",
    "        epoch_X_src, label_src, m_src = src_prgm.get_data(dataset=ds_src,subjects=subjects, return_epochs=True)\n",
    "    return epoch_X_src,label_src,m_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ed80c3-3c0a-40c8-be9c-5b12d84cd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.linalg import sqrtm, inv,pinv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "import os\n",
    "\n",
    "def compute_r_op(X):\n",
    "    r = torch.einsum('bet, tab -> bea',X,X.T).mean(0)\n",
    "    r_op = torch.from_numpy(inv(sqrtm(r)))\n",
    "    return r_op\n",
    "\n",
    "def prepro_data_session(dset_name_path):\n",
    "    with open(os.path.join(path,dset_name_path+'/'+dset_name_path+'_epoch.pkl'), \"rb\") as input_file:\n",
    "        epoch_X = pickle.load(input_file)    \n",
    "        \n",
    "    m_src = pd.read_csv(os.path.join(path,dset_name_path+'/'+dset_name_path+'_m.csv'))\n",
    "    label_src = np.load(os.path.join(path,dset_name_path+'/'+dset_name_path+'_label.npy'))\n",
    "    X_list = []\n",
    "    X_list_raw = []\n",
    "    Y_list = []\n",
    "    #X_list_raw = []\n",
    "    encoder = LabelEncoder()\n",
    "    Y = torch.from_numpy(encoder.fit_transform(label_src)).long()\n",
    "    X = torch.from_numpy(epoch_X.get_data()).float()\n",
    "    del epoch_X,label_src\n",
    "    \n",
    "    for s_id in m_src.subject.unique():\n",
    "        X_list_sub = []\n",
    "        Y_list_sub = []\n",
    "        X_list_raw_sub = []\n",
    "        m_src_i = m_src[m_src['subject']==s_id]\n",
    "        for session in m_src_i.session.unique():\n",
    "            idx = m_src_i[m_src_i['session']==session].index.tolist()\n",
    "            X_s = X[idx]\n",
    "            Y_s = Y[idx]\n",
    "            X_list_raw_sub.append(X_s)\n",
    "            sqrt_R_s = compute_r_op(X_s).float()\n",
    "            X_list_sub.append(torch.einsum(\"fe,bet->bft\",sqrt_R_s, X_s))\n",
    "            Y_list_sub.append(Y_s)\n",
    "            del X_s,Y_s,sqrt_R_s\n",
    "            gc.collect()\n",
    "        X_list.append(X_list_sub)\n",
    "        X_list_raw.append(X_list_raw_sub)\n",
    "        Y_list.append(Y_list_sub)\n",
    "        \n",
    "    torch.save(X_list_raw,os.path.join(path,dset_name_path+'/X_s.pt'))\n",
    "    torch.save(X_list, os.path.join(path,dset_name_path+'/X_EA_s.pt'))\n",
    "    torch.save(Y_list, os.path.join(path,dset_name_path+'/Y_s.pt'))\n",
    "    #return X_list,X_list_raw,Y_list\n",
    "        \n",
    "def prepro_data(dset_name_path):\n",
    "    with open(os.path.join(path,dset_name_path+'/'+dset_name_path+'_epoch.pkl'), \"rb\") as input_file:\n",
    "        epoch_X = pickle.load(input_file)    \n",
    "        \n",
    "    m_src = pd.read_csv(os.path.join(path,dset_name_path+'/'+dset_name_path+'_m.csv'))\n",
    "    label_src = np.load(os.path.join(path,dset_name_path+'/'+dset_name_path+'_label.npy'))\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    X_list_raw = []\n",
    "    encoder = LabelEncoder()\n",
    "    Y = torch.from_numpy(encoder.fit_transform(label_src)).long()\n",
    "    X = torch.from_numpy(epoch_X.get_data()).float()\n",
    "    del epoch_X,label_src\n",
    "    for s_id in m_src.subject.unique():\n",
    "        idx = m_src[m_src['subject']==s_id].index.tolist()\n",
    "        X_s = X[idx]\n",
    "        Y_s = Y[idx]\n",
    "        sqrt_R_s = compute_r_op(X_s).float()\n",
    "        X_list.append(torch.einsum(\"fe,bet->bft\",sqrt_R_s, X_s))\n",
    "        X_list_raw.append(X_s)\n",
    "        Y_list.append(Y_s)\n",
    "        del X_s,Y_s,sqrt_R_s\n",
    "        gc.collect()\n",
    "        \n",
    "    torch.save(X_list_raw,os.path.join(path,dset_name_path+'/X.pt'))\n",
    "    torch.save(X_list, os.path.join(path,dset_name_path+'/X_EA.pt'))\n",
    "    torch.save(Y_list, os.path.join(path,dset_name_path+'/Y.pt'))\n",
    "    \n",
    "    \n",
    "def prepro_data_online(dset_name_path):\n",
    "    with open(os.path.join(path,dset_name_path+'/'+dset_name_path+'_epoch.pkl'), \"rb\") as input_file:\n",
    "        epoch_X = pickle.load(input_file)    \n",
    "        \n",
    "    m_src = pd.read_csv(os.path.join(path,dset_name_path+'/'+dset_name_path+'_m.csv'))\n",
    "    label_src = np.load(os.path.join(path,dset_name_path+'/'+dset_name_path+'_label.npy'))\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    encoder = LabelEncoder()\n",
    "    Y = torch.from_numpy(encoder.fit_transform(label_src)).long()\n",
    "    X = torch.from_numpy(epoch_X.get_data()).float()\n",
    "    del epoch_X,label_src\n",
    "    \n",
    "    for s_id in m_src.subject.unique():\n",
    "        X_list_sub = []\n",
    "        Y_list_sub = []\n",
    "        m_src_i = m_src[m_src['subject']==s_id]\n",
    "        \n",
    "        idx_train = m_src_i[m_src_i['session']=='session_T'].index.tolist()\n",
    "        idx_eval = m_src_i[m_src_i['session']=='session_E'].index.tolist()\n",
    "        X_s_t = X[idx_train]\n",
    "        Y_s_t = Y[idx_train]\n",
    "        X_s_e = X[idx_eval]\n",
    "        Y_s_e = Y[idx_eval]\n",
    "        \n",
    "        sqrt_R_s = compute_r_op(X_s_t).float()\n",
    "        X_list_sub.append(torch.einsum(\"fe,bet->bft\",sqrt_R_s, X_s_t))\n",
    "        Y_list_sub.append(Y_s_t)\n",
    "        \n",
    "        X_list_sub.append(torch.einsum(\"fe,bet->bft\",sqrt_R_s, X_s_e))\n",
    "        Y_list_sub.append(Y_s_e)\n",
    "        \n",
    "        X_list.append(X_list_sub)\n",
    "        Y_list.append(Y_list_sub)\n",
    "    torch.save(X_list, os.path.join(path,dset_name_path+'/X_EA_online.pt'))\n",
    "    torch.save(Y_list, os.path.join(path,dset_name_path+'/Y_online.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697efd62-1c2f-42d8-85a1-c2351e2ee098",
   "metadata": {},
   "source": [
    "## BNCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f62cc15-323e-4719-b720-7e503f0f2611",
   "metadata": {},
   "source": [
    "3 derniers channels = EOG\n",
    "offset de 0.5 = 0.5 * 250 = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3e62b-d1ee-42d7-8c61-9cb7124b96b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chans = ['Fz','FC3','FC1','FCz','FC2','FC4','C5','C3','C1','Cz','C2','C4','C6','CP3','CP1','CPz','CP2','CP4','P1','Pz','P2','POz',\n",
    "             'EOG1','EOG2','EOG3']\n",
    "\n",
    "n_c = 4\n",
    "epoch_X_b,label_src_b,m_src_b =load_data(BNCI2014001,n_c,selected_chans = chans,\n",
    "                                        sfreq = 250,fmin=0,fmax=124.99,tmin=0,tmax=4) #250\n",
    "\n",
    "dset_name_path = 'BNCI'\n",
    "\n",
    "with open(os.path.join(path,dset_name_path+'/'+dset_name_path+'_epoch.pkl'), \"wb\") as output_file:\n",
    "    pickle.dump(epoch_X_b, output_file)\n",
    "    \n",
    "m_src_b.to_csv(os.path.join(path,dset_name_path+'/'+dset_name_path+'_m.csv'),index=False)\n",
    "np.save(os.path.join(path,dset_name_path+'/'+dset_name_path+'_label.npy'), label_src_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b45980-08af-4a51-b4c4-ab4b8d6a035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_data(dset_name_path)\n",
    "prepro_data_session(dset_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8901e370-3d77-483d-85f7-35d7e8a4d65d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35200/3475041729.py:8: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  r = torch.einsum('bet, tab -> bea',X,X.T).mean(0)\n"
     ]
    }
   ],
   "source": [
    "prepro_data_online(dset_name_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d06b6-9c51-4c03-84b4-404eff83264a",
   "metadata": {},
   "source": [
    "## Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0166efa-09ad-44d3-8f02-9587bb700d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#chans = ['Fz','FC3','FC1','FCz','FC2','FC4','C5','C3','C1','Cz','C2','C4','C6','CP3','CP1','CPz','CP2','CP4','P1','Pz','P2','POz',\n",
    "#             'EOG1','EOG2','EOG3']\n",
    "\n",
    "Zhou_chan  = ['Fp1','Fp2','FC3','FCz','FC4','C3','Cz','C4','CP3','CPz','CP4','O1','Oz','O2','VEOU', 'VEOL']\n",
    "\n",
    "\n",
    "n_c = 3\n",
    "epoch_X_z,label_src_z,m_src_z =load_data(Zhou2016,n_c,selected_chans = Zhou_chan,\n",
    "                                        sfreq = 250,fmin=0.5,fmax=124.99,tmin=0,tmax=5) #250\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832ecf6-38b7-4a1d-ab47-bf4a466584b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_name_path = 'Zhou'\n",
    "\n",
    "with open(os.path.join(path,dset_name_path+'/'+dset_name_path+'_epoch.pkl'), \"wb\") as output_file:\n",
    "    pickle.dump(epoch_X_z, output_file)\n",
    "    \n",
    "m_src_z.to_csv(os.path.join(path,dset_name_path+'/'+dset_name_path+'_m.csv'),index=False)\n",
    "np.save(os.path.join(path,dset_name_path+'/'+dset_name_path+'_label.npy'), label_src_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee091544-37c0-40e2-9996-6470bb947a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_data(dset_name_path)\n",
    "prepro_data_session(dset_name_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f94570-d0dc-498c-a521-1883857a674d",
   "metadata": {},
   "source": [
    "## Physionet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d969d3d-8e29-4461-90d3-facdab42a39b",
   "metadata": {},
   "source": [
    "Subjects exclusions References : \n",
    "- Karel Roots, Yar Muhammad, and Naveed Muhammad. Fusion convolutional neural network for cross-subject eeg motor imagery classification. Computers, 9(3):72, 2020.\n",
    "- Jason Sleight, Preeti Pillai, and Shiwali Mohan. Classification of executed and imagined motor movement eeg signals. Ann Arbor: University of Michigan, 110, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6329fb-bfde-4efd-b56e-8bd908a71fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "Physionet_chan = ['FC5','FC3','FC1','FCz','FC2','FC4','FC6','C5','C3','C1','Cz','C2','C4','C6','CP5','CP3','CP1','CPz','CP2',\n",
    "                  'CP4','CP6','Fp1','Fpz','Fp2','AF7','AF3','AFz','AF4','AF8','F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
    "                  'FT7','FT8','T7','T8','T9','T10','TP7','TP8','P7','P5','P3','P1','Pz','P2','P4','P6','P8','PO7','PO3',\n",
    "                  'POz','PO4','PO8','O1','Oz','O2','Iz']\n",
    "\n",
    "n_c = 4\n",
    "subjects_physio = [x for x in list(np.arange(1,110)) if x not in [38,88,89,92,100,104]]\n",
    "\n",
    "epoch_X_p,label_src_p,m_src_p =load_data(PhysionetMI,n_c,selected_chans = Physionet_chan,\n",
    "                                        sfreq = 160,fmin=0,fmax=79.99,tmin=0,tmax=3.5,\n",
    "                                        subjects = subjects_physio) # 160\n",
    "                                         #subjects=subjects_physio)\n",
    "\n",
    "dset_name_path = 'Physionet'\n",
    "\n",
    "with open(os.path.join(path,dset_name_path+'/'+dset_name_path+'_epoch.pkl'), \"wb\") as output_file:\n",
    "    pickle.dump(epoch_X_p, output_file)\n",
    "    \n",
    "m_src_p.to_csv(os.path.join(path,dset_name_path+'/'+dset_name_path+'_m.csv'),index=False)\n",
    "np.save(os.path.join(path,dset_name_path+'/'+dset_name_path+'_label.npy'), label_src_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae685d4-056a-4d37-b2bf-cb10dc96473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_data(dset_name_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f64566-b8c5-4eb3-bfb7-7c9a4091369f",
   "metadata": {},
   "source": [
    "# Cho\n",
    "Subjects exclusions References : \n",
    "- Vinay Jayaram and Alexandre Barachant. Moabb: trustworthy al- gorithm benchmarking for bcis. Journal of neural engineering, 15(6):066011, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776f939-618f-4cc0-ac79-c85f912e0b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Cho2017_chan = ['Fp1','AF7','AF3','F1','F3','F5','F7','FT7','FC5','FC3','FC1','C1','C3','C5','T7','TP7','CP5','CP3','CP1','P1',\n",
    "                'P3','P5','P7','P9','PO7','PO3','O1','Iz','Oz','POz','Pz','CPz','Fpz','Fp2','AF8','AF4','AFz','Fz','F2','F4','F6'\n",
    "                ,'F8','FT8','FC6','FC4','FC2','FCz','Cz','C2','C4','C6','T8','TP8','CP6','CP4','CP2','P2','P4','P6','P8','P10','PO8','PO4','O2']\n",
    "n_c = 2\n",
    "subjects_cho = [x for x in list(np.arange(1,53)) if x not in [32, 46, 49]]\n",
    "epoch_X_c,label_src_c,m_src_c =load_data(Cho2017,n_c,selected_chans = Cho2017_chan,\n",
    "                                         sfreq = 512,fmin=0.5,fmax=255.99,tmin=0,tmax=3,\n",
    "                                         subjects = subjects_cho) # 512\n",
    "\n",
    "dset_name_path = 'Cho'\n",
    "\n",
    "with open(os.path.join(path,dset_name_path+'/'+dset_name_path+'_epoch.pkl'), \"wb\") as output_file:\n",
    "    pickle.dump(epoch_X_c, output_file)\n",
    "    \n",
    "m_src_c.to_csv(os.path.join(path,dset_name_path+'/'+dset_name_path+'_m.csv'),index=False)\n",
    "np.save(os.path.join(path,dset_name_path+'/'+dset_name_path+'_label.npy'), label_src_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166f2cd-ca8f-4224-b7a8-7a06b97da135",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_data(dset_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626af80-1961-4132-9dda-eabca8e11906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_yass",
   "language": "python",
   "name": "env_yass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
